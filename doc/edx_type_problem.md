{
  u'definition': ObjectId('561c628556c02c484b1bb5de'),
  u'block_type': u'problem',
  u'block_id': u'5fcc159afeff4d54bee7b5c685f6a9fd',
  u'fields': {
    u'markdown': u'Dropdown problems allow learners to select only one option from a list of options.\n\nWhen you add the problem, be sure to select Settings to specify a Display Name and other values that apply.\n\nYou can use the following example problem as a model.\n\n >>Which of the following countries celebrates its independence on August 15?<<\n\n [[(India), Spain, China, Bermuda]]\n\n [explanation]\n India became an independent nation on August 15, 1947.\n [explanation]\n',
    u'display_name': u'Dropdown',
    u'children': [

    ]
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': 4L,
    u'previous_version': ObjectId('561c62ae56c02c484b1bb5e8'),
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    10,
    13,
    1,
    54,
    55,
    84000),
    u'source_version': ObjectId('561c628556c02c484b1bb5df'),
    u'update_version': ObjectId('561c646f56c02c484b1bb5e9')
  }
}{
  u'definition': ObjectId('561c629f56c02c484b1bb5e5'),
  u'block_type': u'problem',
  u'block_id': u'b8867a79166446fa9e432681adde1ba2',
  u'fields': {
    u'markdown': u'Dropdown problems allow learners to select only one option from a list of options.\n\nWhen you add the problem, be sure to select Settings to specify a Display Name and other values that apply.\n\nYou can use the following example problem as a model.\n\n >>Which of the following countries celebrates its independence on August 15?<<\n\n [[(India), Spain, China, Bermuda]]\n\n [explanation]\n India became an independent nation on August 15, 1947.\n [explanation]\n',
    u'display_name': u'Dropdown',
    u'children': [

    ]
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': 4L,
    u'previous_version': ObjectId('561c62a156c02c484b1bb5e7'),
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    10,
    13,
    1,
    54,
    55,
    93000),
    u'source_version': ObjectId('561c629f56c02c484b1bb5e6'),
    u'update_version': ObjectId('561c646f56c02c484b1bb5e9')
  }
}{
  u'definition': ObjectId('561c624856c02c484b1bb5d8'),
  u'block_type': u'problem',
  u'block_id': u'9d6a3b976a1c461ab6a182eab3ee28e8',
  u'fields': {
    u'markdown': u'Checkbox problems allow learners to select multiple options. Learners can see all the options along with the problem text.\n\nWhen you add the problem, be sure to select Settings to specify a Display Name and other values that apply.\n\nYou can use the following example problem as a model.\n\n>>The following languages are in the Indo-European family:<<\n[x] Urdu\n[ ] Finnish\n[x] Marathi\n[x] French\n[ ] Hungarian\n\nNote: Make sure you select all of the correct options\u2014there may be more than one!\n\n[explanation]\nUrdu, Marathi, and French are all Indo-European languages, while Finnish and Hungarian are in the Uralic family.\n[explanation]\n',
    u'display_name': u'Checkboxes',
    u'children': [

    ]
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': 4L,
    u'previous_version': ObjectId('561c627056c02c484b1bb5db'),
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    10,
    13,
    1,
    54,
    55,
    69000),
    u'source_version': ObjectId('561c624856c02c484b1bb5d9'),
    u'update_version': ObjectId('561c646f56c02c484b1bb5e9')
  }
}{
  u'definition': ObjectId('56351d1156c02c09b3e48bf2'),
  u'block_type': u'problem',
  u'block_id': u'72a7b6e71d5b4476848eeda0e54330c2',
  u'fields': {
    u'markdown': None,
    u'display_name': u'Drag Text only - squares',
    u'children': [

    ],
    u'showanswer': u'attempted',
    u'xml_attributes': {
      u'filename': [
        u'problem/72a7b6e71d5b4476848eeda0e54330c2.xml',
        u'problem/72a7b6e71d5b4476848eeda0e54330c2.xml'
      ]
    }
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': 4L,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    10,
    31,
    19,
    57,
    5,
    267000),
    u'source_version': ObjectId('56351d0756c02c09b3e48abc'),
    u'update_version': ObjectId('56351d0756c02c09b3e48abd')
  }
}{
  u'definition': ObjectId('56351d1256c02c09b3e48bff'),
  u'block_type': u'problem',
  u'block_id': u'6f5d1a7dc42740a1b0ab21a3e8157d25',
  u'fields': {
    u'markdown': None,
    u'display_name': u'One rectangular region',
    u'xml_attributes': {
      u'filename': [
        u'problem/6f5d1a7dc42740a1b0ab21a3e8157d25.xml',
        u'problem/6f5d1a7dc42740a1b0ab21a3e8157d25.xml'
      ]
    },
    u'children': [

    ]
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': 4L,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    10,
    31,
    19,
    57,
    6,
    298000),
    u'source_version': ObjectId('56351d0756c02c09b3e48abc'),
    u'update_version': ObjectId('56351d0756c02c09b3e48abd')
  }
}{
  u'definition': ObjectId('56351d1156c02c09b3e48bfa'),
  u'block_type': u'problem',
  u'block_id': u'dbec24c43a8b4d34a0186714cd8b1828',
  u'fields': {
    u'markdown': None,
    u'display_name': u'Images only - unordered_equal rule',
    u'children': [

    ],
    u'showanswer': u'attempted',
    u'xml_attributes': {
      u'filename': [
        u'problem/dbec24c43a8b4d34a0186714cd8b1828.xml',
        u'problem/dbec24c43a8b4d34a0186714cd8b1828.xml'
      ]
    }
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': 4L,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    10,
    31,
    19,
    57,
    5,
    920000),
    u'source_version': ObjectId('56351d0756c02c09b3e48abc'),
    u'update_version': ObjectId('56351d0756c02c09b3e48abd')
  }
}{
  u'definition': ObjectId('56351d0e56c02c09b3e48bd1'),
  u'block_type': u'problem',
  u'block_id': u'91e1a9ed821f4279bb68e8bbc28eeeb3',
  u'fields': {
    u'markdown': u'\nYou can provide feedback for each available option in a dropdown problem.\n\nYou can also add hints for learners.\n\nBe sure to select Settings to specify a Display Name and other values that apply.\n\nUse the following example problem as a model.\n\n>> A/an ________ is a vegetable.<<\n\n[[\n    apple {{An apple is the fertilized ovary that comes from an apple tree and contains seeds, meaning it is a fruit.}}\n    pumpkin {{A pumpkin is the fertilized ovary of a squash plant and contains seeds, meaning it is a fruit.}}\n    (potato) {{A potato is an edible part of a plant in tuber form and is a vegetable.}}\n    tomato {{Many people mistakenly think a tomato is a vegetable. However, because a tomato is the fertilized ovary of a tomato plant and contains seeds, it is a fruit.}}\n]]\n\n||A fruit is the fertilized ovary from a flower.||\n||A fruit contains seeds of the plant.||\n',
    u'display_name': u'Dropdown with Hints and Feedback',
    u'xml_attributes': {
      u'filename': [
        u'problem/91e1a9ed821f4279bb68e8bbc28eeeb3.xml',
        u'problem/91e1a9ed821f4279bb68e8bbc28eeeb3.xml'
      ]
    },
    u'children': [

    ]
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': 4L,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    10,
    31,
    19,
    57,
    2,
    747000),
    u'source_version': ObjectId('56351d0756c02c09b3e48abc'),
    u'update_version': ObjectId('56351d0756c02c09b3e48abd')
  }
}{
  u'definition': ObjectId('56351d1256c02c09b3e48c01'),
  u'block_type': u'problem',
  u'block_id': u'65600ca921544d34880306e3d2ec5897',
  u'fields': {
    u'markdown': None,
    u'display_name': u'Multiple rectangular regions',
    u'xml_attributes': {
      u'filename': [
        u'problem/65600ca921544d34880306e3d2ec5897.xml',
        u'problem/65600ca921544d34880306e3d2ec5897.xml'
      ]
    },
    u'children': [

    ]
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': 4L,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    10,
    31,
    19,
    57,
    6,
    438000),
    u'source_version': ObjectId('56351d0756c02c09b3e48abc'),
    u'update_version': ObjectId('56351d0756c02c09b3e48abd')
  }
}{
  u'definition': ObjectId('56351d0e56c02c09b3e48bcb'),
  u'block_type': u'problem',
  u'block_id': u'62a40d9279164bb0a3afe6a081a3aa16',
  u'fields': {
    u'markdown': u'In text input problems, also known as "fill-in-the-blank" problems, learners enter text into a response field. The text can include letters and characters such as punctuation marks. The text that the learner enters must match your specified answer text exactly. You can specify more than one correct answer. Learners must enter a response that matches one of the correct answers exactly.\n\nWhen you add the problem, be sure to select Settings to specify a Display Name and other values that apply.\n\nYou can use the following example problem as a model.\n\n>>What was the first post-secondary school in China to allow both male and female students?<<\n\n= Nanjing Higher Normal Institute\nor= National Central University\nor= Nanjing University\n\n[explanation]\nNanjing Higher Normal Institute first admitted female students in 1920.\n[explanation]\n',
    u'display_name': u'Text Input',
    u'xml_attributes': {
      u'filename': [
        u'problem/62a40d9279164bb0a3afe6a081a3aa16.xml',
        u'problem/62a40d9279164bb0a3afe6a081a3aa16.xml'
      ]
    },
    u'children': [

    ]
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': 4L,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    10,
    31,
    19,
    57,
    2,
    294000),
    u'source_version': ObjectId('56351d0756c02c09b3e48abc'),
    u'update_version': ObjectId('56351d0756c02c09b3e48abd')
  }
}{
  u'definition': ObjectId('56351d1156c02c09b3e48bf6'),
  u'block_type': u'problem',
  u'block_id': u'cde3f0f8f08c40b884eebb86586033b0',
  u'fields': {
    u'markdown': None,
    u'display_name': u'Images only - any rule',
    u'children': [

    ],
    u'showanswer': u'attempted',
    u'xml_attributes': {
      u'filename': [
        u'problem/cde3f0f8f08c40b884eebb86586033b0.xml',
        u'problem/cde3f0f8f08c40b884eebb86586033b0.xml'
      ]
    }
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': 4L,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    10,
    31,
    19,
    57,
    5,
    601000),
    u'source_version': ObjectId('56351d0756c02c09b3e48abc'),
    u'update_version': ObjectId('56351d0756c02c09b3e48abd')
  }
}{
  u'definition': ObjectId('56351d0e56c02c09b3e48bd4'),
  u'block_type': u'problem',
  u'block_id': u'8d6c884f29884971b884a32e5932a489',
  u'fields': {
    u'markdown': u'\nYou can provide feedback for each option in a multiple choice problem.\n\nYou can also add hints for learners.\n\nBe sure to select Settings to specify a Display Name and other values that apply.\n\nUse the following example problem as a model.\n\n>>Which of the following is a vegetable?<<\n( ) apple {{An apple is the fertilized ovary that comes from an apple tree and contains seeds, meaning it is a fruit.}}\n( ) pumpkin {{A pumpkin is the fertilized ovary of a squash plant and contains seeds, meaning it is a fruit.}}\n(x) potato {{A potato is an edible part of a plant in tuber form and is a vegetable.}}\n( ) tomato {{Many people mistakenly think a tomato is a vegetable. However, because a tomato is the fertilized ovary of a tomato plant and contains seeds, it is a fruit.}}\n\n||A fruit is the fertilized ovary from a flower.||\n||A fruit contains seeds of the plant.||\n',
    u'display_name': u'Multiple Choice with Hints and Feedback',
    u'xml_attributes': {
      u'filename': [
        u'problem/8d6c884f29884971b884a32e5932a489.xml',
        u'problem/8d6c884f29884971b884a32e5932a489.xml'
      ]
    },
    u'children': [

    ]
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': 4L,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    10,
    31,
    19,
    57,
    2,
    943000),
    u'source_version': ObjectId('56351d0756c02c09b3e48abc'),
    u'update_version': ObjectId('56351d0756c02c09b3e48abd')
  }
}{
  u'definition': ObjectId('56351d0f56c02c09b3e48bde'),
  u'block_type': u'problem',
  u'block_id': u'5352cfcbee66410d9517ee76bc7e870b',
  u'fields': {
    u'markdown': None,
    u'display_name': u'Default',
    u'xml_attributes': {
      u'filename': [
        u'problem/5352cfcbee66410d9517ee76bc7e870b.xml',
        u'problem/5352cfcbee66410d9517ee76bc7e870b.xml'
      ]
    },
    u'children': [

    ]
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': 4L,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    10,
    31,
    19,
    57,
    3,
    723000),
    u'source_version': ObjectId('56351d0756c02c09b3e48abc'),
    u'update_version': ObjectId('56351d0756c02c09b3e48abd')
  }
}{
  u'definition': ObjectId('56351d1256c02c09b3e48bfd'),
  u'block_type': u'problem',
  u'block_id': u'cdc4c3edc8b34fe399805c3c4ae5565a',
  u'fields': {
    u'markdown': None,
    u'display_name': u'Image Mapped Input',
    u'xml_attributes': {
      u'filename': [
        u'problem/cdc4c3edc8b34fe399805c3c4ae5565a.xml',
        u'problem/cdc4c3edc8b34fe399805c3c4ae5565a.xml'
      ]
    },
    u'children': [

    ]
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': 4L,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    10,
    31,
    19,
    57,
    6,
    159000),
    u'source_version': ObjectId('56351d0756c02c09b3e48abc'),
    u'update_version': ObjectId('56351d0756c02c09b3e48abd')
  }
}{
  u'definition': ObjectId('56351d1256c02c09b3e48c06'),
  u'block_type': u'problem',
  u'block_id': u'f0575f2d54314071a83c902880431c8e',
  u'fields': {
    u'markdown': None,
    u'display_name': u'Math Expression Input',
    u'xml_attributes': {
      u'filename': [
        u'problem/f0575f2d54314071a83c902880431c8e.xml',
        u'problem/f0575f2d54314071a83c902880431c8e.xml'
      ]
    },
    u'children': [

    ]
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': 4L,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    10,
    31,
    19,
    57,
    6,
    924000),
    u'source_version': ObjectId('56351d0756c02c09b3e48abc'),
    u'update_version': ObjectId('56351d0756c02c09b3e48abd')
  }
}{
  u'definition': ObjectId('56351d0f56c02c09b3e48bd7'),
  u'block_type': u'problem',
  u'block_id': u'f5204e74fd7e4d7486fd8daa8602b973',
  u'fields': {
    u'markdown': u'\nYou can provide feedback for correct answers in numerical input problems. You cannot provide feedback for incorrect answers.\n\nUse feedback for the correct answer to reinforce the process for arriving at the numerical value.\n\nYou can also add hints for learners.\n\nBe sure to select Settings to specify a Display Name and other values that apply.\n\nUse the following example problem as a model.\n\n>>What is the arithmetic mean for the following set of numbers? (1, 5, 6, 3, 5)<<\n\n= 4 {{The mean for this set of numbers is 20 / 5, which equals 4.}}\n\n||The mean is calculated by summing the set of numbers and dividing by n.||\n||n is the count of items in the set.||\n\n[explanation]\nThe mean is calculated by summing the set of numbers and dividing by n. In this case: (1 + 5 + 6 + 3 + 5) / 5 = 20 / 5 = 4.\n[explanation]\n',
    u'display_name': u'Numerical Input with Hints and Feedback',
    u'xml_attributes': {
      u'filename': [
        u'problem/f5204e74fd7e4d7486fd8daa8602b973.xml',
        u'problem/f5204e74fd7e4d7486fd8daa8602b973.xml'
      ]
    },
    u'children': [

    ]
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': 4L,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    10,
    31,
    19,
    57,
    3,
    140000),
    u'source_version': ObjectId('56351d0756c02c09b3e48abc'),
    u'update_version': ObjectId('56351d0756c02c09b3e48abd')
  }
}{
  u'definition': ObjectId('56351d2056c02c09b3e48c8d'),
  u'block_type': u'problem',
  u'block_id': u'61142fab24b04062a6b51bc1bc9c62c2',
  u'fields': {
    u'markdown': None,
    u'display_name': u'Jasmine tests: JS Input problem edition (same origin)',
    u'xml_attributes': {
      u'filename': [
        u'problem/61142fab24b04062a6b51bc1bc9c62c2.xml',
        u'problem/61142fab24b04062a6b51bc1bc9c62c2.xml'
      ]
    },
    u'matlab_api_key': u'NotAValidMathlabKey',
    u'showanswer': u'never',
    u'children': [

    ]
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': 4L,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    10,
    31,
    19,
    57,
    20,
    974000),
    u'source_version': ObjectId('56351d0756c02c09b3e48abc'),
    u'update_version': ObjectId('56351d0756c02c09b3e48abd')
  }
}{
  u'definition': ObjectId('56351d1456c02c09b3e48c1c'),
  u'block_type': u'problem',
  u'block_id': u'6eee6907bf1c4711a60e637377ccc62a',
  u'fields': {
    u'markdown': None,
    u'display_name': u'Protein Builder Tool',
    u'xml_attributes': {
      u'filename': [
        u'problem/6eee6907bf1c4711a60e637377ccc62a.xml',
        u'problem/6eee6907bf1c4711a60e637377ccc62a.xml'
      ]
    },
    u'children': [

    ]
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': 4L,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    10,
    31,
    19,
    57,
    8,
    927000),
    u'source_version': ObjectId('56351d0756c02c09b3e48abc'),
    u'update_version': ObjectId('56351d0756c02c09b3e48abd')
  }
}{
  u'definition': ObjectId('56351d1456c02c09b3e48c19'),
  u'block_type': u'problem',
  u'block_id': u'f882de960c104d7b839373c62b87bc76',
  u'fields': {
    u'markdown': None,
    u'display_name': u'Gene Explorer tool',
    u'children': [

    ],
    u'showanswer': u'attempted',
    u'xml_attributes': {
      u'filename': [
        u'problem/f882de960c104d7b839373c62b87bc76.xml',
        u'problem/f882de960c104d7b839373c62b87bc76.xml'
      ]
    }
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': 4L,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    10,
    31,
    19,
    57,
    8,
    665000),
    u'source_version': ObjectId('56351d0756c02c09b3e48abc'),
    u'update_version': ObjectId('56351d0756c02c09b3e48abd')
  }
}{
  u'definition': ObjectId('56351d0c56c02c09b3e48bb8'),
  u'block_type': u'problem',
  u'block_id': u'68990661ba354cedb46bd284b9a07013',
  u'fields': {
    u'markdown': u'',
    u'display_name': u'Blank Common Problem',
    u'xml_attributes': {
      u'filename': [
        u'problem/68990661ba354cedb46bd284b9a07013.xml',
        u'problem/68990661ba354cedb46bd284b9a07013.xml'
      ]
    },
    u'children': [

    ]
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': 4L,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    10,
    31,
    19,
    57,
    1,
    21000),
    u'source_version': ObjectId('56351d0756c02c09b3e48abc'),
    u'update_version': ObjectId('56351d0756c02c09b3e48abd')
  }
}{
  u'definition': ObjectId('56351d1156c02c09b3e48bf8'),
  u'block_type': u'problem',
  u'block_id': u'e44889e3fd3a4230ba0ac7d2da927ff1',
  u'fields': {
    u'markdown': None,
    u'display_name': u'Text only - Unordered equal rule',
    u'children': [

    ],
    u'showanswer': u'attempted',
    u'xml_attributes': {
      u'filename': [
        u'problem/e44889e3fd3a4230ba0ac7d2da927ff1.xml',
        u'problem/e44889e3fd3a4230ba0ac7d2da927ff1.xml'
      ]
    }
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': 4L,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    10,
    31,
    19,
    57,
    5,
    775000),
    u'source_version': ObjectId('56351d0756c02c09b3e48abc'),
    u'update_version': ObjectId('56351d0756c02c09b3e48abd')
  }
}{
  u'definition': ObjectId('56351d1156c02c09b3e48bf0'),
  u'block_type': u'problem',
  u'block_id': u'325193d54bfd4c5cb6d64c1498fd3fa3',
  u'fields': {
    u'markdown': None,
    u'display_name': u'Drag and Drop',
    u'children': [

    ],
    u'showanswer': u'never',
    u'xml_attributes': {
      u'filename': [
        u'problem/325193d54bfd4c5cb6d64c1498fd3fa3.xml',
        u'problem/325193d54bfd4c5cb6d64c1498fd3fa3.xml'
      ]
    }
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': 4L,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    10,
    31,
    19,
    57,
    5,
    100000),
    u'source_version': ObjectId('56351d0756c02c09b3e48abc'),
    u'update_version': ObjectId('56351d0756c02c09b3e48abd')
  }
}{
  u'definition': ObjectId('56351d1b56c02c09b3e48c5b'),
  u'block_type': u'problem',
  u'block_id': u'15858bfed68148659cc19ab510450e78',
  u'fields': {
    u'markdown': u'>>Which of the following countries has the largest population?<<\n( ) Brazil {{ timely feedback -- explain why an almost correct answer is wrong }}\n( ) Germany\n(x) Indonesia\n( ) Russia\n\n',
    u'display_name': u'Base problem 1',
    u'xml_attributes': {
      u'filename': [
        u'problem/15858bfed68148659cc19ab510450e78.xml',
        u'problem/15858bfed68148659cc19ab510450e78.xml'
      ]
    },
    u'children': [

    ]
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': 4L,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    10,
    31,
    19,
    57,
    15,
    417000),
    u'source_version': ObjectId('56351d0756c02c09b3e48abc'),
    u'update_version': ObjectId('56351d0756c02c09b3e48abd')
  }
}{
  u'definition': ObjectId('56351d1b56c02c09b3e48c5c'),
  u'block_type': u'problem',
  u'block_id': u'05976a80a8b04e898d27f34af7ff8501',
  u'fields': {
    u'markdown': u' >>Which of the following countries celebrates its independence on August 15?<<\n\n [[(India), Spain, China, Bermuda]]\n\n [explanation]\n India became an independent nation on August 15, 1947.\n [explanation]\n',
    u'display_name': u'BASE PROBLEM 2',
    u'xml_attributes': {
      u'filename': [
        u'problem/05976a80a8b04e898d27f34af7ff8501.xml',
        u'problem/05976a80a8b04e898d27f34af7ff8501.xml'
      ]
    },
    u'children': [

    ]
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': 4L,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    10,
    31,
    19,
    57,
    15,
    504000),
    u'source_version': ObjectId('56351d0756c02c09b3e48abc'),
    u'update_version': ObjectId('56351d0756c02c09b3e48abd')
  }
}{
  u'definition': ObjectId('56351d1356c02c09b3e48c11'),
  u'block_type': u'problem',
  u'block_id': u'd9f9b580afaf4b88b53dfb5d9dcb6bb4',
  u'fields': {
    u'markdown': None,
    u'display_name': u'Problem with Adaptive Hint',
    u'xml_attributes': {
      u'filename': [
        u'problem/d9f9b580afaf4b88b53dfb5d9dcb6bb4.xml',
        u'problem/d9f9b580afaf4b88b53dfb5d9dcb6bb4.xml'
      ]
    },
    u'children': [

    ]
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': 4L,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    10,
    31,
    19,
    57,
    7,
    833000),
    u'source_version': ObjectId('56351d0756c02c09b3e48abc'),
    u'update_version': ObjectId('56351d0756c02c09b3e48abd')
  }
}{
  u'definition': ObjectId('56351d1256c02c09b3e48c03'),
  u'block_type': u'problem',
  u'block_id': u'298700a2aa2c4b43a1d96e9f5715b586',
  u'fields': {
    u'markdown': None,
    u'display_name': u'irregular region',
    u'xml_attributes': {
      u'filename': [
        u'problem/298700a2aa2c4b43a1d96e9f5715b586.xml',
        u'problem/298700a2aa2c4b43a1d96e9f5715b586.xml'
      ]
    },
    u'children': [

    ]
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': 4L,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    10,
    31,
    19,
    57,
    6,
    591000),
    u'source_version': ObjectId('56351d0756c02c09b3e48abc'),
    u'update_version': ObjectId('56351d0756c02c09b3e48abd')
  }
}{
  u'definition': ObjectId('56351d0d56c02c09b3e48bc2'),
  u'block_type': u'problem',
  u'block_id': u'a80d8f3d6b334a07875f4a8ed8595684',
  u'fields': {
    u'markdown': u'Dropdown problems allow learners to select only one option from a list of options.\n\nWhen you add the problem, be sure to select Settings to specify a Display Name and other values that apply.\n\nYou can use the following example problem as a model.\n\n >>Which of the following countries celebrates its independence on August 15?<<\n\n [[(India), Spain, China, Bermuda]]\n\n [explanation]\n India became an independent nation on August 15, 1947.\n [explanation]\n',
    u'display_name': u'Dropdown',
    u'xml_attributes': {
      u'filename': [
        u'problem/a80d8f3d6b334a07875f4a8ed8595684.xml',
        u'problem/a80d8f3d6b334a07875f4a8ed8595684.xml'
      ]
    },
    u'children': [

    ]
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': 4L,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    10,
    31,
    19,
    57,
    1,
    645000),
    u'source_version': ObjectId('56351d0756c02c09b3e48abc'),
    u'update_version': ObjectId('56351d0756c02c09b3e48abd')
  }
}{
  u'definition': ObjectId('56351d0d56c02c09b3e48bc5'),
  u'block_type': u'problem',
  u'block_id': u'4ec5a82326f34f58ab6fe61635445ff3',
  u'fields': {
    u'markdown': u'Multiple choice problems allow learners to select only one option. Learners can see all the options along with the problem text.\n\nWhen you add the problem, be sure to select Settings to specify a Display Name and other values that apply.\n\nYou can use the following example problem as a model.\n\n>>Which of the following countries has the largest population?<<\n( ) Brazil {{ timely feedback -- explain why an almost correct answer is wrong }}\n( ) Germany\n(x) Indonesia\n( ) Russia\n\n[explanation]\nAccording to September 2014 estimates:\nThe population of Indonesia is approximately 250 million.\nThe population of Brazil  is approximately 200 million.\nThe population of Russia is approximately 146 million.\nThe population of Germany is approximately 81 million.\n[explanation]\n',
    u'display_name': u'Multiple Choice',
    u'xml_attributes': {
      u'filename': [
        u'problem/4ec5a82326f34f58ab6fe61635445ff3.xml',
        u'problem/4ec5a82326f34f58ab6fe61635445ff3.xml'
      ]
    },
    u'children': [

    ]
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': 4L,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    10,
    31,
    19,
    57,
    1,
    834000),
    u'source_version': ObjectId('56351d0756c02c09b3e48abc'),
    u'update_version': ObjectId('56351d0756c02c09b3e48abd')
  }
}{
  u'definition': ObjectId('56351d0e56c02c09b3e48bce'),
  u'block_type': u'problem',
  u'block_id': u'197fffa596a74b018f0f94a3834e2416',
  u'fields': {
    u'markdown': u'\nYou can provide feedback for each option in a checkbox problem, with distinct feedback depending on whether or not the learner selects that option.\n\nYou can also provide compound feedback for a specific combination of answers. For example, if you have three possible answers in the problem, you can configure specific feedback for when a learner selects each combination of possible answers.\n\nYou can also add hints for learners.\n\nBe sure to select Settings to specify a Display Name and other values that apply.\n\nUse the following example problem as a model.\n\n>>Which of the following is a fruit? Check all that apply.<<\n\n[x] apple  {{ selected: You are correct that an apple is a fruit because it is the fertilized ovary that comes from an apple tree and contains seeds. }, { unselected: Remember that an apple is also a fruit.}}\n[x] pumpkin {{ selected: You are correct that a pumpkin is a fruit because it is the fertilized ovary of a squash plant and contains seeds. }, { unselected: Remember that a pumpkin is also a fruit.}}\n[ ] potato   {{ U: You are correct that a potato is a vegetable because it is an edible part of a plant in tuber form.}, { S: A potato is a vegetable, not a fruit, because it does not come from a flower and does not contain seeds.}}\n[x] tomato  {{ S: You are correct that a tomato is a fruit because it is the fertilized ovary of a tomato plant and contains seeds. }, { U: Many people mistakenly think a tomato is a vegetable. However, because a tomato is the fertilized ovary of a tomato plant and contains seeds, it is a fruit.}}\n\n\n{{ ((A B D)) An apple, pumpkin, and tomato are all fruits as they all are fertilized ovaries of a plant and contain seeds. }}\n{{ ((A B C D)) You are correct that an apple, pumpkin, and tomato are all fruits as they all are fertilized ovaries of a plant and contain seeds. However, a potato is not a fruit as it is an edible part of a plant in tuber form and is a vegetable.  }}\n\n||A fruit is the fertilized ovary from a flower.||\n||A fruit contains seeds of the plant.||\n',
    u'display_name': u'Checkboxes with Hints and Feedback',
    u'xml_attributes': {
      u'filename': [
        u'problem/197fffa596a74b018f0f94a3834e2416.xml',
        u'problem/197fffa596a74b018f0f94a3834e2416.xml'
      ]
    },
    u'children': [

    ]
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': 4L,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    10,
    31,
    19,
    57,
    2,
    555000),
    u'source_version': ObjectId('56351d0756c02c09b3e48abc'),
    u'update_version': ObjectId('56351d0756c02c09b3e48abd')
  }
}{
  u'definition': ObjectId('56351d1056c02c09b3e48beb'),
  u'block_type': u'problem',
  u'block_id': u'a5585f3785814916a2f553e07e1c5703',
  u'fields': {
    u'markdown': None,
    u'display_name': u'Custom Python-Evaluated Input',
    u'xml_attributes': {
      u'filename': [
        u'problem/a5585f3785814916a2f553e07e1c5703.xml',
        u'problem/a5585f3785814916a2f553e07e1c5703.xml'
      ]
    },
    u'children': [

    ]
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': 4L,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    10,
    31,
    19,
    57,
    4,
    708000),
    u'source_version': ObjectId('56351d0756c02c09b3e48abc'),
    u'update_version': ObjectId('56351d0756c02c09b3e48abd')
  }
}{
  u'definition': ObjectId('56351d1056c02c09b3e48be8'),
  u'block_type': u'problem',
  u'block_id': u'577dd44e2f614afe993ee0964135d25d',
  u'fields': {
    u'markdown': None,
    u'display_name': u'Custom Javascript Display and Grading',
    u'children': [

    ],
    u'showanswer': u'never',
    u'xml_attributes': {
      u'filename': [
        u'problem/577dd44e2f614afe993ee0964135d25d.xml',
        u'problem/577dd44e2f614afe993ee0964135d25d.xml'
      ]
    }
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': 4L,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    10,
    31,
    19,
    57,
    4,
    453000),
    u'source_version': ObjectId('56351d0756c02c09b3e48abc'),
    u'update_version': ObjectId('56351d0756c02c09b3e48abd')
  }
}{
  u'definition': ObjectId('56351d1456c02c09b3e48c16'),
  u'block_type': u'problem',
  u'block_id': u'4ad0337664104b738b790a8b8cd06a15',
  u'fields': {
    u'markdown': None,
    u'display_name': u'Chemical Equation',
    u'xml_attributes': {
      u'filename': [
        u'problem/4ad0337664104b738b790a8b8cd06a15.xml',
        u'problem/4ad0337664104b738b790a8b8cd06a15.xml'
      ]
    },
    u'children': [

    ]
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': 4L,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    10,
    31,
    19,
    57,
    8,
    344000),
    u'source_version': ObjectId('56351d0756c02c09b3e48abc'),
    u'update_version': ObjectId('56351d0756c02c09b3e48abd')
  }
}{
  u'definition': ObjectId('56351d1156c02c09b3e48bf4'),
  u'block_type': u'problem',
  u'block_id': u'd488f754cd024e9c94b996faeb70f1de',
  u'fields': {
    u'markdown': None,
    u'display_name': u'Drag images only - exact rule',
    u'children': [

    ],
    u'showanswer': u'attempted',
    u'xml_attributes': {
      u'filename': [
        u'problem/d488f754cd024e9c94b996faeb70f1de.xml',
        u'problem/d488f754cd024e9c94b996faeb70f1de.xml'
      ]
    }
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': 4L,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    10,
    31,
    19,
    57,
    5,
    436000),
    u'source_version': ObjectId('56351d0756c02c09b3e48abc'),
    u'update_version': ObjectId('56351d0756c02c09b3e48abd')
  }
}{
  u'definition': ObjectId('56351d0e56c02c09b3e48bc8'),
  u'block_type': u'problem',
  u'block_id': u'12643ee4335e4776861836cccb2b48cb',
  u'fields': {
    u'markdown': u'In a numerical input problem, learners enter numbers or a specific and relatively simple mathematical expression. Learners enter the response in plain text, and the system then converts the text to a symbolic expression that learners can see below the response field.\n\nThe system can handle several types of characters, including basic operators, fractions, exponents, and common constants such as "i". You can refer learners to "Entering Mathematical and Scientific Expressions" in the edX Guide for Students for more information.\n\nWhen you add the problem, be sure to select Settings to specify a Display Name and other values that apply.\n\nYou can use the following example problems as models.\n\n>>How many miles away from Earth is the sun? Use scientific notation to answer.<<\n\n= 9.3*10^7 \nor= 9.296*10^7 \n\n>>The square of what number is -100?<<\n\n= 10*i \n\n[explanation]\nThe sun is 93,000,000, or 9.3*10^7, miles away from Earth.\n-100 is the square of 10 times the imaginary number, i.\n[explanation]\n',
    u'display_name': u'Numerical Input',
    u'xml_attributes': {
      u'filename': [
        u'problem/12643ee4335e4776861836cccb2b48cb.xml',
        u'problem/12643ee4335e4776861836cccb2b48cb.xml'
      ]
    },
    u'children': [

    ]
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': 4L,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    10,
    31,
    19,
    57,
    2,
    50000),
    u'source_version': ObjectId('56351d0756c02c09b3e48abc'),
    u'update_version': ObjectId('56351d0756c02c09b3e48abd')
  }
}{
  u'definition': ObjectId('56351d0d56c02c09b3e48bbd'),
  u'block_type': u'problem',
  u'block_id': u'7d0679d59abe443c909d6abcc7f1c111',
  u'fields': {
    u'markdown': u'Checkbox problems allow learners to select multiple options. Learners can see all the options along with the problem text.\n\nWhen you add the problem, be sure to select Settings to specify a Display Name and other values that apply.\n\nYou can use the following example problem as a model.\n\n>>The following languages are in the Indo-European family:<<\n[x] Urdu\n[ ] Finnish\n[x] Marathi\n[x] French\n[ ] Hungarian\n\nNote: Make sure you select all of the correct options\u2014there may be more than one!\n\n[explanation]\nUrdu, Marathi, and French are all Indo-European languages, while Finnish and Hungarian are in the Uralic family.\n[explanation]\n',
    u'display_name': u'Checkboxes',
    u'xml_attributes': {
      u'filename': [
        u'problem/7d0679d59abe443c909d6abcc7f1c111.xml',
        u'problem/7d0679d59abe443c909d6abcc7f1c111.xml'
      ]
    },
    u'children': [

    ]
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': 4L,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    10,
    31,
    19,
    57,
    1,
    338000),
    u'source_version': ObjectId('56351d0756c02c09b3e48abc'),
    u'update_version': ObjectId('56351d0756c02c09b3e48abd')
  }
}{
  u'definition': ObjectId('56351d0f56c02c09b3e48bda'),
  u'block_type': u'problem',
  u'block_id': u'f9fe4049bc1a44d783a774ebbd7fd1cd',
  u'fields': {
    u'markdown': u'\nYou can provide feedback for the correct answer in text input problems, as well as for specific incorrect answers.\n\nUse feedback on expected incorrect answers to address common misconceptions and to provide guidance on how to arrive at the correct answer.\n\nBe sure to select Settings to specify a Display Name and other values that apply.\n\nUse the following example problem as a model.\n\n>>Which U.S. state has the largest land area?<<\n\n=Alaska {{Alaska is 576,400 square miles, more than double the land area\nof the second largest state, Texas.}}\n\nnot=Texas {{While many people think Texas is the largest state, it is actually the second largest, with 261,797 square miles.}}\n\nnot=California {{California is the third largest state, with 155,959 square miles.}}\n\n||Consider the square miles, not population.||\n||Consider all 50 states, not just the continental United States.||\n',
    u'display_name': u'Text Input with Hints and Feedback',
    u'xml_attributes': {
      u'filename': [
        u'problem/f9fe4049bc1a44d783a774ebbd7fd1cd.xml',
        u'problem/f9fe4049bc1a44d783a774ebbd7fd1cd.xml'
      ]
    },
    u'children': [

    ]
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': 4L,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    10,
    31,
    19,
    57,
    3,
    339000),
    u'source_version': ObjectId('56351d0756c02c09b3e48abc'),
    u'update_version': ObjectId('56351d0756c02c09b3e48abd')
  }
}{
  u'definition': ObjectId('56351d1056c02c09b3e48be3'),
  u'block_type': u'problem',
  u'block_id': u'0f820c189d14406aaab2c30e19278ae7',
  u'fields': {
    u'markdown': None,
    u'display_name': u'Circuit Schematic Builder',
    u'xml_attributes': {
      u'filename': [
        u'problem/0f820c189d14406aaab2c30e19278ae7.xml',
        u'problem/0f820c189d14406aaab2c30e19278ae7.xml'
      ]
    },
    u'children': [

    ]
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': 4L,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    10,
    31,
    19,
    57,
    4,
    120000),
    u'source_version': ObjectId('56351d0756c02c09b3e48abc'),
    u'update_version': ObjectId('56351d0756c02c09b3e48abd')
  }
}{
  u'definition': ObjectId('56351d1356c02c09b3e48c09'),
  u'block_type': u'problem',
  u'block_id': u'bb200523478348e3af899005f9d94472',
  u'fields': {
    u'markdown': None,
    u'display_name': u'Molecular Structure',
    u'xml_attributes': {
      u'filename': [
        u'problem/bb200523478348e3af899005f9d94472.xml',
        u'problem/bb200523478348e3af899005f9d94472.xml'
      ]
    },
    u'children': [

    ]
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': 4L,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    10,
    31,
    19,
    57,
    7,
    209000),
    u'source_version': ObjectId('56351d0756c02c09b3e48abc'),
    u'update_version': ObjectId('56351d0756c02c09b3e48abd')
  }
}{
  u'definition': ObjectId('55c3e2da56c02c317615a87a'),
  u'block_type': u'problem',
  u'block_id': u'651e0945b77f42e0a4c89b8c3e6f5b3b',
  u'fields': {
    u'markdown': u"Occasionally, you might submit a correct answer and continue experimenting with possible answers. That is great! Exploring all of the possible correct answers is a very effective way to learn. However, you should remember to leave your final answer with a green check mark next to it. The edX system will only count your most recent answer towards your final grade, so if your extra experiments leave your answer in an incorrect state, then you will not get credit for the problem. \n\nEnter the numerical value of Pi:\n= 3.14159 +- .02\n\n[explanation] Pi, or the the ratio between a circle's circumference to its diameter, is an irrational number known to extreme precision. It is value is approximately equal to 3.14. [explanation] ",
    u'display_name': u'Answering More Than Once',
    u'weight': None,
    u'rerandomize': u'never',
    u'xml_attributes': {
      u'filename': [
        u'problem/651e0945b77f42e0a4c89b8c3e6f5b3b.xml',
        u'problem/651e0945b77f42e0a4c89b8c3e6f5b3b.xml'
      ]
    },
    u'children': [

    ],
    u'showanswer': u'always',
    u'max_attempts': None
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': -1,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    8,
    6,
    22,
    42,
    34,
    64000),
    u'source_version': ObjectId('55c3e2d556c02c3176159eb6'),
    u'update_version': ObjectId('55c3e2d556c02c3176159eb8')
  }
}{
  u'definition': ObjectId('55c3e2d956c02c317615a831'),
  u'block_type': u'problem',
  u'block_id': u'Sample_ChemFormula_Problem',
  u'fields': {
    u'rerandomize': u'never',
    u'display_name': u'Chemical Equations',
    u'children': [

    ],
    u'showanswer': u'never',
    u'xml_attributes': {
      u'filename': [
        u'problem/Sample_ChemFormula_Problem.xml',
        u'problem/Sample_ChemFormula_Problem.xml'
      ]
    }
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': -1,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    8,
    6,
    22,
    42,
    33,
    756000),
    u'source_version': ObjectId('55c3e2d556c02c3176159eb6'),
    u'update_version': ObjectId('55c3e2d556c02c3176159eb8')
  }
}{
  u'definition': ObjectId('55c3e2d956c02c317615a84b'),
  u'block_type': u'problem',
  u'block_id': u'700x_editmolB',
  u'fields': {
    u'showanswer': u'attempted',
    u'display_name': u'Molecule Editor',
    u'weight': None,
    u'graceperiod': u'18000 seconds',
    u'xqa_key': u'qaijS3UatK020Wc0sfCtFe0V6jpB4d64',
    u'rerandomize': u'never',
    u'start': datetime.datetime(2013,
    2,
    5,
    0,
    0),
    u'xml_attributes': {
      u'filename': [
        u'problem/700x_editmolB.xml',
        u'problem/700x_editmolB.xml'
      ]
    },
    u'children': [

    ]
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': -1,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    8,
    6,
    22,
    42,
    33,
    878000),
    u'source_version': ObjectId('55c3e2d556c02c3176159eb6'),
    u'update_version': ObjectId('55c3e2d556c02c3176159eb8')
  }
}{
  u'definition': ObjectId('55c3e2d956c02c317615a81b'),
  u'block_type': u'problem',
  u'block_id': u'9cee77a606ea4c1aa5440e0ea5d0f618',
  u'fields': {
    u'showanswer': u'always',
    u'display_name': u'Interactive Questions',
    u'weight': None,
    u'rerandomize': u'never',
    u'xml_attributes': {
      u'filename': [
        u'problem/9cee77a606ea4c1aa5440e0ea5d0f618.xml',
        u'problem/9cee77a606ea4c1aa5440e0ea5d0f618.xml'
      ]
    },
    u'children': [

    ],
    u'max_attempts': None
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': -1,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    8,
    6,
    22,
    42,
    33,
    673000),
    u'source_version': ObjectId('55c3e2d556c02c3176159eb6'),
    u'update_version': ObjectId('55c3e2d556c02c3176159eb8')
  }
}{
  u'definition': ObjectId('55c3e2d956c02c317615a837'),
  u'block_type': u'problem',
  u'block_id': u'0d759dee4f9d459c8956136dbde55f02',
  u'fields': {
    u'markdown': u"Here's a very simple example of a text input question. Depending on the course you may have to observe special text requirements for dates, case sensitivity, etc. \n\nWhich country contains Paris as its capital?\n= France\n[explanation]\nYou can find verification that Paris is the capital of France on wikipedia, or any atlas that you have at hand.\n[explanation]\n",
    u'display_name': u'Text Input',
    u'weight': None,
    u'rerandomize': u'never',
    u'xml_attributes': {
      u'filename': [
        u'problem/0d759dee4f9d459c8956136dbde55f02.xml',
        u'problem/0d759dee4f9d459c8956136dbde55f02.xml'
      ]
    },
    u'children': [

    ],
    u'showanswer': u'always',
    u'max_attempts': None
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': -1,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    8,
    6,
    22,
    42,
    33,
    778000),
    u'source_version': ObjectId('55c3e2d556c02c3176159eb6'),
    u'update_version': ObjectId('55c3e2d556c02c3176159eb8')
  }
}{
  u'definition': ObjectId('55c3e2da56c02c317615a881'),
  u'block_type': u'problem',
  u'block_id': u'ex_practice_3',
  u'fields': {
    u'rerandomize': u'always',
    u'display_name': u'Randomized Questions',
    u'children': [

    ],
    u'showanswer': u'never',
    u'xml_attributes': {
      u'filename': [
        u'problem/ex_practice_3.xml',
        u'problem/ex_practice_3.xml'
      ]
    }
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': -1,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    8,
    6,
    22,
    42,
    34,
    90000),
    u'source_version': ObjectId('55c3e2d556c02c3176159eb6'),
    u'update_version': ObjectId('55c3e2d556c02c3176159eb8')
  }
}{
  u'definition': ObjectId('55c3e2d956c02c317615a854'),
  u'block_type': u'problem',
  u'block_id': u'logic_gate_problem',
  u'fields': {
    u'markdown': None,
    u'display_name': u'',
    u'graceperiod': u'18000 seconds',
    u'xqa_key': u'qaijS3UatK020Wc0sfCtFe0V6jpB4d64',
    u'rerandomize': u'never',
    u'start': datetime.datetime(2013,
    2,
    5,
    0,
    0),
    u'xml_attributes': {
      u'filename': [
        u'problem/logic_gate_problem.xml',
        u'problem/logic_gate_problem.xml'
      ]
    },
    u'children': [

    ],
    u'showanswer': u'always'
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': -1,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    8,
    6,
    22,
    42,
    33,
    912000),
    u'source_version': ObjectId('55c3e2d556c02c3176159eb6'),
    u'update_version': ObjectId('55c3e2d556c02c3176159eb8')
  }
}{
  u'definition': ObjectId('55c3e2d956c02c317615a834'),
  u'block_type': u'problem',
  u'block_id': u'75f9562c77bc4858b61f907bb810d974',
  u'fields': {
    u'markdown': u'Some course questions ask that you insert numbers into web-text fields, and your answers can be judged exactly - or approximately - according to the question. \n\nNote that the edX system uses a period to indicate decimals, so fifteen and three quarters is written "15.75", not "15,75". \n\nEnter the numerical value of Pi:\n= 3.14159 +- .02\n\nEnter the approximate value of 502*9:\n= 4518 +- 15%\n\nEnter the number of fingernails on a healthy human hand. For the purposes of this question, please consider the thumb as a finger:\n= 5\n\n[explanation] Pi, or the the ratio between a circle\'s circumference to its diameter, is an irrational number known to extreme precision. It is value is approximately equal to 3.14.\nAlthough you can get an exact value by typing 502*9 into a calculator, the result will be close to 500*10, or 5,000. The grader accepts any response within 15% of the true value, 4518, so that you can use any estimation technique that you like.\nThe index finger, middle finger, ring finger, pinky, and thumb are the five different fingers on a human hand.[explanation] ',
    u'display_name': u'Numerical Input',
    u'weight': None,
    u'rerandomize': u'never',
    u'xml_attributes': {
      u'filename': [
        u'problem/75f9562c77bc4858b61f907bb810d974.xml',
        u'problem/75f9562c77bc4858b61f907bb810d974.xml'
      ]
    },
    u'children': [

    ],
    u'showanswer': u'always',
    u'max_attempts': None
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': -1,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    8,
    6,
    22,
    42,
    33,
    767000),
    u'source_version': ObjectId('55c3e2d556c02c3176159eb6'),
    u'update_version': ObjectId('55c3e2d556c02c3176159eb8')
  }
}{
  u'definition': ObjectId('55c3e2d956c02c317615a82b'),
  u'block_type': u'problem',
  u'block_id': u'a0effb954cca4759994f1ac9e9434bf4',
  u'fields': {
    u'markdown': u'Many edX courses have homework or exercises you need to complete.  Notice the clock image to the left?  That means this homework or exercise needs to be completed for you to pass the course. (This can be a bit confusing; the exercise may or may not have a due date prior to the end of the course.)\n\nWe\u2019ve provided eight (8) examples of how a professor might ask you questions. While the multiple choice question types below are somewhat standard, explore the other question types in the sequence above, like the formula builder- try them all out. \n\nAs you go through the question types, notice how edX gives you immediate feedback on your responses - it really helps in the learning process.\n\nWhat color is the open ocean on a sunny day?\n\n[[yellow, (blue), green]]\n\n\nWhich piece of furniture is built for sitting?\n\n( ) a table\n( ) a desk\n(x) a chair\n( ) a bookshelf\n\nWhich of the following are musical instruments?\n\n[x] a piano\n[ ] a tree\n[x] a guitar\n[ ] a window\n\n\n ',
    u'display_name': u'Multiple Choice Questions',
    u'weight': None,
    u'rerandomize': u'never',
    u'xml_attributes': {
      u'filename': [
        u'problem/a0effb954cca4759994f1ac9e9434bf4.xml',
        u'problem/a0effb954cca4759994f1ac9e9434bf4.xml'
      ]
    },
    u'children': [

    ],
    u'showanswer': u'never',
    u'max_attempts': None
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': -1,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    8,
    6,
    22,
    42,
    33,
    735000),
    u'source_version': ObjectId('55c3e2d556c02c3176159eb6'),
    u'update_version': ObjectId('55c3e2d556c02c3176159eb8')
  }
}{
  u'definition': ObjectId('55c3e2d956c02c317615a825'),
  u'block_type': u'problem',
  u'block_id': u'c554538a57664fac80783b99d9d6da7c',
  u'fields': {
    u'showanswer': u'always',
    u'display_name': u'Pointing on a Picture',
    u'weight': None,
    u'rerandomize': u'never',
    u'xml_attributes': {
      u'filename': [
        u'problem/c554538a57664fac80783b99d9d6da7c.xml',
        u'problem/c554538a57664fac80783b99d9d6da7c.xml'
      ]
    },
    u'children': [

    ],
    u'max_attempts': None
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': -1,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    8,
    6,
    22,
    42,
    33,
    713000),
    u'source_version': ObjectId('55c3e2d556c02c3176159eb6'),
    u'update_version': ObjectId('55c3e2d556c02c3176159eb8')
  }
}{
  u'definition': ObjectId('55c3e2da56c02c317615a87d'),
  u'block_type': u'problem',
  u'block_id': u'ex_practice_limited_checks',
  u'fields': {
    u'showanswer': u'never',
    u'display_name': u'Limited Checks',
    u'rerandomize': u'never',
    u'xml_attributes': {
      u'filename': [
        u'problem/ex_practice_limited_checks.xml',
        u'problem/ex_practice_limited_checks.xml'
      ]
    },
    u'children': [

    ],
    u'max_attempts': 100
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': -1,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    8,
    6,
    22,
    42,
    34,
    75000),
    u'source_version': ObjectId('55c3e2d556c02c3176159eb6'),
    u'update_version': ObjectId('55c3e2d556c02c3176159eb8')
  }
}{
  u'definition': ObjectId('55c3e2da56c02c317615a877'),
  u'block_type': u'problem',
  u'block_id': u'45d46192272c4f6db6b63586520bbdf4',
  u'fields': {
    u'markdown': u'In some courses a "show answer" button might appear below a question. When you click on this button, you can see the correct answer (with an explanation) that would receive full credit. \n\nHow much does it cost to take an edX course? Enter the number of dollars.\n\n= 0 \n\n[explanation]\nIt costs zero dollars to take an edX course. All edX courses are free to students.\n[explanation]\n\n\n\n',
    u'display_name': u'Getting Answers',
    u'weight': None,
    u'rerandomize': u'never',
    u'xml_attributes': {
      u'filename': [
        u'problem/45d46192272c4f6db6b63586520bbdf4.xml',
        u'problem/45d46192272c4f6db6b63586520bbdf4.xml'
      ]
    },
    u'children': [

    ],
    u'showanswer': u'always',
    u'max_attempts': None
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': -1,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    8,
    6,
    22,
    42,
    34,
    53000),
    u'source_version': ObjectId('55c3e2d556c02c3176159eb6'),
    u'update_version': ObjectId('55c3e2d556c02c3176159eb8')
  }
}{
  u'definition': ObjectId('55c3e2d956c02c317615a84f'),
  u'block_type': u'problem',
  u'block_id': u'python_grader',
  u'fields': {
    u'markdown': None,
    u'display_name': u'',
    u'graceperiod': u'18000 seconds',
    u'xqa_key': u'qaijS3UatK020Wc0sfCtFe0V6jpB4d64',
    u'rerandomize': u'never',
    u'start': datetime.datetime(2013,
    2,
    5,
    0,
    0),
    u'xml_attributes': {
      u'title': u'Embedded Code Box',
      u'filename': [
        u'problem/python_grader.xml',
        u'problem/python_grader.xml'
      ]
    },
    u'children': [

    ],
    u'showanswer': u'always'
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': -1,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    8,
    6,
    22,
    42,
    33,
    893000),
    u'source_version': ObjectId('55c3e2d556c02c3176159eb6'),
    u'update_version': ObjectId('55c3e2d556c02c3176159eb8')
  }
}{
  u'definition': ObjectId('55c3e2d956c02c317615a82e'),
  u'block_type': u'problem',
  u'block_id': u'Sample_Algebraic_Problem',
  u'fields': {
    u'showanswer': u'attempted',
    u'display_name': u'Mathematical Expressions',
    u'graceperiod': u'18000 seconds',
    u'xqa_key': u'qaijS3UatK020Wc0sfCtFe0V6jpB4d64',
    u'rerandomize': u'never',
    u'start': datetime.datetime(2013,
    2,
    5,
    0,
    0),
    u'xml_attributes': {
      u'filename': [
        u'problem/Sample_Algebraic_Problem.xml',
        u'problem/Sample_Algebraic_Problem.xml'
      ]
    },
    u'children': [

    ]
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': -1,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    8,
    6,
    22,
    42,
    33,
    746000),
    u'source_version': ObjectId('55c3e2d556c02c3176159eb6'),
    u'update_version': ObjectId('55c3e2d556c02c3176159eb8')
  }
}{
  u'definition': ObjectId('55c3e2da56c02c317615a87e'),
  u'block_type': u'problem',
  u'block_id': u'd1b84dcd39b0423d9e288f27f0f7f242',
  u'fields': {
    u'showanswer': u'never',
    u'display_name': u'Few Checks',
    u'weight': None,
    u'rerandomize': u'never',
    u'xml_attributes': {
      u'filename': [
        u'problem/d1b84dcd39b0423d9e288f27f0f7f242.xml',
        u'problem/d1b84dcd39b0423d9e288f27f0f7f242.xml'
      ]
    },
    u'children': [

    ],
    u'max_attempts': 3
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': -1,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    8,
    6,
    22,
    42,
    34,
    79000),
    u'source_version': ObjectId('55c3e2d556c02c3176159eb6'),
    u'update_version': ObjectId('55c3e2d556c02c3176159eb8')
  }
}{
  u'definition': ObjectId('55c3e2d956c02c317615a821'),
  u'block_type': u'problem',
  u'block_id': u'303034da25524878a2e66fb57c91cf85',
  u'fields': {
    u'markdown': u"Two alternative explanations are offered for the fact that the key would not open any of the doors. Which one is correct?\n\n( ) The key was too small.\n( ) The locks were too large. \n(x) Neither - because there is no 'correct' frame of reference, the only true statement can be that there was no lock-to-key match.\n",
    u'display_name': u'Attributing Blame',
    u'xml_attributes': {
      u'filename': [
        u'problem/303034da25524878a2e66fb57c91cf85.xml',
        u'problem/303034da25524878a2e66fb57c91cf85.xml'
      ]
    },
    u'rerandomize': u'never',
    u'showanswer': u'finished',
    u'children': [

    ]
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': -1,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    8,
    6,
    22,
    42,
    33,
    696000),
    u'source_version': ObjectId('55c3e2d556c02c3176159eb6'),
    u'update_version': ObjectId('55c3e2d556c02c3176159eb8')
  }
}{
  u'definition': ObjectId('55c3e2da56c02c317615a874'),
  u'block_type': u'problem',
  u'block_id': u'ex_practice_2',
  u'fields': {
    u'rerandomize': u'never',
    u'display_name': u'Immediate Feedback',
    u'children': [

    ],
    u'showanswer': u'never',
    u'xml_attributes': {
      u'filename': [
        u'problem/ex_practice_2.xml',
        u'problem/ex_practice_2.xml'
      ]
    }
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': -1,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    8,
    6,
    22,
    42,
    34,
    42000),
    u'source_version': ObjectId('55c3e2d556c02c3176159eb6'),
    u'update_version': ObjectId('55c3e2d556c02c3176159eb8')
  }
}{
  u'definition': ObjectId('55c3e2d956c02c317615a820'),
  u'block_type': u'problem',
  u'block_id': u'932e6f2ce8274072a355a94560216d1a',
  u'fields': {
    u'markdown': u'The paragraph contains references to sleepiness and an unexpected event. Why?\n\n( ) Feeling sleepy can cause white rabbits to appear.\n( ) There is foreshadowing of a tea party.\n(x) There is an implication that the strangeness to follow can be considered like a dream.\n\n',
    u'display_name': u'Perchance to Dream',
    u'xml_attributes': {
      u'filename': [
        u'problem/932e6f2ce8274072a355a94560216d1a.xml',
        u'problem/932e6f2ce8274072a355a94560216d1a.xml'
      ]
    },
    u'rerandomize': u'never',
    u'showanswer': u'always',
    u'children': [

    ]
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': -1,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    8,
    6,
    22,
    42,
    33,
    692000),
    u'source_version': ObjectId('55c3e2d556c02c3176159eb6'),
    u'update_version': ObjectId('55c3e2d556c02c3176159eb8')
  }
}{
  u'definition': ObjectId('55c3e2d956c02c317615a828'),
  u'block_type': u'problem',
  u'block_id': u'd2e35c1d294b4ba0b3b1048615605d2a',
  u'fields': {
    u'markdown': None,
    u'display_name': u'Drag and Drop',
    u'weight': None,
    u'rerandomize': u'never',
    u'xml_attributes': {
      u'filename': [
        u'problem/d2e35c1d294b4ba0b3b1048615605d2a.xml',
        u'problem/d2e35c1d294b4ba0b3b1048615605d2a.xml'
      ]
    },
    u'children': [

    ],
    u'showanswer': u'never',
    u'max_attempts': None
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': -1,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    8,
    6,
    22,
    42,
    33,
    724000),
    u'source_version': ObjectId('55c3e2d556c02c3176159eb6'),
    u'update_version': ObjectId('55c3e2d556c02c3176159eb8')
  }
}{
  u'definition': ObjectId('55c3e2d956c02c317615a858'),
  u'block_type': u'problem',
  u'block_id': u'700x_proteinmake',
  u'fields': {
    u'showanswer': u'always',
    u'display_name': u'Designing Proteins in Two Dimensions',
    u'weight': None,
    u'graceperiod': u'',
    u'xqa_key': u'qaijS3UatK020Wc0sfCtFe0V6jpB4d64',
    u'rerandomize': u'never',
    u'start': datetime.datetime(2013,
    2,
    5,
    0,
    0),
    u'xml_attributes': {
      u'filename': [
        u'problem/700x_proteinmake.xml',
        u'problem/700x_proteinmake.xml'
      ]
    },
    u'children': [

    ],
    u'max_attempts': None
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': -1,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    8,
    6,
    22,
    42,
    33,
    927000),
    u'source_version': ObjectId('55c3e2d556c02c3176159eb6'),
    u'update_version': ObjectId('55c3e2d556c02c3176159eb8')
  }
}{
  u'definition': ObjectId('55c3e2d956c02c317615a853'),
  u'block_type': u'problem',
  u'block_id': u'free_form_simulation',
  u'fields': {
    u'markdown': None,
    u'display_name': u'',
    u'graceperiod': u'18000 seconds',
    u'xqa_key': u'qaijS3UatK020Wc0sfCtFe0V6jpB4d64',
    u'rerandomize': u'never',
    u'start': datetime.datetime(2013,
    2,
    5,
    0,
    0),
    u'xml_attributes': {
      u'filename': [
        u'problem/free_form_simulation.xml',
        u'problem/free_form_simulation.xml'
      ]
    },
    u'children': [

    ],
    u'showanswer': u'never'
  },
  u'defaults': {

  },
  u'edit_info': {
    u'edited_by': -1,
    u'previous_version': None,
    u'original_usage_version': None,
    u'original_usage': None,
    u'edited_on': datetime.datetime(2015,
    8,
    6,
    22,
    42,
    33,
    907000),
    u'source_version': ObjectId('55c3e2d556c02c3176159eb6'),
    u'update_version': ObjectId('55c3e2d556c02c3176159eb8')
  }
}
